# CSI-Assignment---Week-6


# ğŸš€ Model Evaluation & Hyperparameter Tuning  
> _Celebal Technologies Summer Internship 2025 â€“ Week 6 Assignment by Debargha Karmakar_

---

## ğŸ§  Overview

This project focuses on building, evaluating, and optimizing machine learning models for binary classification using the **Breast Cancer Wisconsin Diagnostic Dataset**. The models are not only trained but also fine-tuned using **advanced hyperparameter tuning techniques** to extract their best possible performance.

This isn't just about code â€” it's about **clarity**, **impact**, and **insight**.

---

## ğŸ¯ Objective

- Train multiple machine learning models.
- Evaluate them using diverse performance metrics.
- Tune them with **GridSearchCV** and **RandomizedSearchCV**.
- Visualize results for clear interpretation.
- Identify and recommend the best-performing model.

> ğŸ’¡ The problem weâ€™re solving is not academic â€” itâ€™s real. Early diagnosis of breast cancer saves lives. Every model trained in this notebook carries that weight.

---

## ğŸ“¦ Technologies Used

| Tool/Library          | Purpose                          |
|----------------------|----------------------------------|
| `Python`             | Core programming language        |
| `scikit-learn`       | Machine learning models          |
| `matplotlib` & `seaborn` | Visualizations               |
| `pandas`, `numpy`    | Data manipulation                |
| `GridSearchCV`       | Exhaustive hyperparameter tuning |
| `RandomizedSearchCV` | Efficient hyperparameter tuning  |

---

## ğŸ“‚ Project Structure
```
model-evaluation-hyperparameter-tuning/
â”‚
â”œâ”€â”€ main.py # Complete ML pipeline
â”œâ”€â”€ README.md # Project documentation
â”œâ”€â”€ outputs/ # Saved results & visualizations
â”‚ â”œâ”€â”€ classification_report.txt
â”‚ â”œâ”€â”€ confusion_matrix_lr.png
â”‚ â”œâ”€â”€ confusion_matrix_rf.png
â”‚ â”œâ”€â”€ confusion_matrix_svm.png
â”‚ â”œâ”€â”€ feature_importance_rf.png
â”‚ â”œâ”€â”€ model_comparison.png
â”‚ â”œâ”€â”€ model_performance_summary.csv
â”‚ â””â”€â”€ roc_curve_rf.png
```

---

## ğŸ” Models Trained

- âœ… Logistic Regression
- ğŸŒ² Random Forest Classifier
- ğŸ’  Support Vector Machine (SVM)

Each model was evaluated using:

- **Accuracy**
- **Precision**
- **Recall**
- **F1-Score**

And their performance was visualized through confusion matrices, ROC curves, and summary bar plots.

---

## ğŸ§ª Hyperparameter Tuning

| Technique         | Applied To        | Purpose                            |
|------------------|-------------------|------------------------------------|
| `GridSearchCV`   | Random Forest     | Best parameters via grid search    |
| `RandomizedSearchCV` | SVM           | Quick scan of hyperparameter space |

---

## ğŸ“Š Visualizations

All visualizations are saved in the `Outputs/` folder.

### ğŸ“ˆ Model Comparison
![Model Comparison](Outputs/model_comparison.png)

### ğŸ§¬ Feature Importance (Random Forest)
![Feature Importance](Outputs/feature_importance_rf.png)

### ğŸ§ª ROC Curve (Random Forest)
![ROC Curve](Outputs/roc_curve_rf.png)

### âœ… Confusion Matrices
Each model's confusion matrix is saved separately for clarity.

---

## ğŸ“ Outputs Included

- `classification_report.txt` â€“ Detailed reports for all models
- `model_performance_summary.csv` â€“ Tabular comparison
- PNG plots of confusion matrices, ROC curve, model comparison, feature importance

---


## âš™ï¸ How to Run

1. Clone this repo:
   ```bash
   git clone https://github.com/yourusername/model-evaluation-hyperparameter-tuning.git
   cd model-evaluation-hyperparameter-tuning
